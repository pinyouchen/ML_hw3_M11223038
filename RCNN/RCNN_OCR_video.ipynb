{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file found at D:/test3/RCNN/best_model.pth\n",
      "Correct numbers dictionary:\n",
      "FFAU2895947: FFAU2895947\n",
      "MAGU5605323 : MAGU5605323 \n",
      "SEKU5875349: SEKU5875349\n",
      "SEKU5877491: SEKU5877491\n",
      "SEKU6026686: SEKU6026686\n",
      "TCNU6246126: TCNU6246126\n",
      "TLLU4080736: TLLU4080736\n",
      "TRHU8927462: TRHU8927462\n",
      "TSSU5017340: TSSU5017340\n",
      "TSSU5029819: TSSU5029819\n",
      "TSSU5042071: TSSU5042071\n",
      "TSSU5061615: TSSU5061615\n",
      "TSSU5099400: TSSU5099400\n",
      "TSSU5142300: TSSU5142300\n",
      "TSSU5160351: TSSU5160351\n",
      "WHLU5591798: WHLU5591798\n",
      "WHLU5842825: WHLU5842825\n",
      "WHSU2483178: WHSU2483178\n",
      "WHSU2615314: WHSU2615314\n",
      "WHSU2864765: WHSU2864765\n",
      "WHSU5223791: WHSU5223791\n",
      "WHSU5295430: WHSU5295430\n",
      "WHSU5368199: WHSU5368199\n",
      "WHSU5563298: WHSU5563298\n",
      "WHSU5610492: WHSU5610492\n",
      "WHSU5628589: WHSU5628589\n",
      "WHSU5744465: WHSU5744465\n",
      "WHSU5927851: WHSU5927851\n",
      "WHSU5991104: WHSU5991104\n",
      "WHSU5998393: WHSU5998393\n",
      "WHSU6010260: WHSU6010260\n",
      "WHSU6040178: WHSU6040178\n",
      "WHSU6052306: WHSU6052306\n",
      "WHSU6167120: WHSU6167120\n",
      "WHSU6557387: WHSU6557387\n",
      "WHSU6651665: WHSU6651665\n",
      "WHSU6728690: WHSU6728690\n",
      "WHSU6856285: WHSU6856285\n",
      "WHSU6892256: WHSU6892256\n",
      "Video: SEKU5875349.avi, Extracted stem: SEKU5875349, Correct number: SEKU5875349\n",
      "Video: TLLU4080736.avi, Extracted stem: TLLU4080736, Correct number: TLLU4080736\n",
      "Video: TSSU5099400.avi, Extracted stem: TSSU5099400, Correct number: TSSU5099400\n",
      "Video: WHSU2483178.avi, Extracted stem: WHSU2483178, Correct number: WHSU2483178\n",
      "Video: WHSU5223791.avi, Extracted stem: WHSU5223791, Correct number: WHSU5223791\n",
      "Video: WHSU5368199.avi, Extracted stem: WHSU5368199, Correct number: WHSU5368199\n",
      "Video: WHSU5927851.avi, Extracted stem: WHSU5927851, Correct number: WHSU5927851\n",
      "Video: WHSU6167120.avi, Extracted stem: WHSU6167120, Correct number: WHSU6167120\n",
      "Video: WHSU6728690.avi, Extracted stem: WHSU6728690, Correct number: WHSU6728690\n",
      "Video: WHSU6892256.avi, Extracted stem: WHSU6892256, Correct number: WHSU6892256\n",
      "所有结果已记录在 results_log.txt 中。\n",
      "Overall OCR Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageOps,ImageFont\n",
    "import pytesseract\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=weights)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model_path = \"D:/test3/RCNN/best_model.pth\"\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "else:\n",
    "    print(f\"Model file found at {model_path}\")\n",
    "\n",
    "model = get_model_instance_segmentation(num_classes=2)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "video_folder = \"D:/test3/video_dataset1\"\n",
    "results_folder = 'D:/test3/OCR-video-results2'\n",
    "frames_folder = \"D:/test3/OCR-frames2\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "correct_numbers_folder = \"D:/test3/picture_test_sataset/picture_test_sataset\"\n",
    "correct_numbers = {Path(file_name).stem: Path(file_name).stem for file_name in os.listdir(correct_numbers_folder)}\n",
    "\n",
    "print(\"Correct numbers dictionary:\")\n",
    "for k, v in correct_numbers.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "font_path = \"arial.ttf\"\n",
    "font_size = 35\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "def is_valid_container_number(number):\n",
    "    if len(number) < 11:\n",
    "        return False\n",
    "    if not number[10].isdigit():\n",
    "        return False\n",
    "    return calculate_check_digit(number[:10]) == int(number[10])\n",
    "\n",
    "def calculate_check_digit(code):\n",
    "    values = {'A': 10, 'B': 12, 'C': 13, 'D': 14, 'E': 15, 'F': 16, 'G': 17, 'H': 18, 'I': 19, 'J': 20,\n",
    "              'K': 21, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'R': 29, 'S': 30, 'T': 31,\n",
    "              'U': 32, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38}\n",
    "    try:\n",
    "        s = sum(values[code[i]] * (2 ** i) for i in range(4)) + sum(int(code[i + 4]) * (2 ** (i + 4)) for i in range(6))\n",
    "        return s % 11 % 10\n",
    "    except (KeyError, ValueError):\n",
    "        return -1\n",
    "\n",
    "def adjust_box(x1, y1, x2, y2, scale=1.2):\n",
    "    \"\"\"\n",
    "    调整框的大小。\n",
    "    \n",
    "    :param x1: 左上角x坐标\n",
    "    :param y1: 左上角y坐标\n",
    "    :param x2: 右下角x坐标\n",
    "    :param y2: 右下角y坐标\n",
    "    :param scale: 调整比例（默认为1.2）\n",
    "    :return: 调整后的坐标\n",
    "    \"\"\"\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "    new_width = width * scale\n",
    "    new_height = height * scale\n",
    "    \n",
    "    new_x1 = x1 - (new_width - width) / 2\n",
    "    new_y1 = y1 - (new_height - height) / 2\n",
    "    new_x2 = x2 + (new_width - width) / 2\n",
    "    new_y2 = y2 + (new_height - height) / 2\n",
    "    \n",
    "    return new_x1, new_y1, new_x2, new_y2\n",
    "\n",
    "def preprocess_image_and_save(img, save_path):\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(2)\n",
    "\n",
    "    img = ImageOps.grayscale(img)\n",
    "\n",
    "    img = img.point(lambda x: 0 if x < 128 else 255, '1')\n",
    "\n",
    "    img.save(save_path)\n",
    "\n",
    "    return img\n",
    "\n",
    "results_log = os.path.join(results_folder, \"results_log.txt\")\n",
    "with open(results_log, \"w\", encoding=\"utf-8\") as log_file:\n",
    "    overall_correct_count = 0\n",
    "    overall_total_count = 0\n",
    "    \n",
    "    for video_file in os.listdir(video_folder):\n",
    "        if video_file.endswith(\".mp4\") or video_file.endswith(\".avi\"):\n",
    "            video_path = os.path.join(video_folder, video_file)\n",
    "            video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "            frame_width = int(video_capture.get(3))\n",
    "            frame_height = int(video_capture.get(4))\n",
    "            output_path = os.path.join(results_folder, f\"{Path(video_file).stem}_processed.avi\")\n",
    "            out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 10, (frame_width, frame_height))\n",
    "\n",
    "            frame_results = defaultdict(int)\n",
    "            correct_count = 0\n",
    "            total_count = 0\n",
    "            frame_idx = 0\n",
    "\n",
    "            video_stem = Path(video_file).stem\n",
    "            video_frames_folder = os.path.join(frames_folder, video_stem)\n",
    "            os.makedirs(video_frames_folder, exist_ok=True)\n",
    "\n",
    "            correct_number = correct_numbers.get(video_stem, \"\")\n",
    "\n",
    "            print(f\"Video: {video_file}, Extracted stem: {video_stem}, Correct number: {correct_number}\")\n",
    "\n",
    "            while video_capture.isOpened():\n",
    "                ret, frame = video_capture.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "                \n",
    "                transform = transforms.Compose([transforms.ToTensor()])\n",
    "                img = transform(image).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    prediction = model([img])\n",
    "                \n",
    "                detected_objects = prediction[0]['boxes'].cpu().numpy()\n",
    "                scores = prediction[0]['scores'].cpu().numpy()\n",
    "\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                for obj, score in zip(detected_objects, scores):\n",
    "                    if score > 0.5:\n",
    "                        x1, y1, x2, y2 = adjust_box(*obj)\n",
    "                        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "                        cropped_img = image.crop((x1, y1, x2, y2))\n",
    "                        cropped_output_path = os.path.join(video_frames_folder, f\"{video_stem}_frame_{frame_idx}_cropped.jpg\")\n",
    "                        cropped_img.save(cropped_output_path)\n",
    "                        \n",
    "                        custom_config = r'--oem 3 --psm 6'\n",
    "                        processed_img = preprocess_image_and_save(cropped_img, os.path.join(video_frames_folder, f\"{video_stem}_frame_{frame_idx}_processed.jpg\"))\n",
    "                        recognized_text = pytesseract.image_to_string(processed_img, config=custom_config)\n",
    "                        recognized_text = ''.join(filter(str.isalnum, recognized_text))\n",
    "                        \n",
    "                        if is_valid_container_number(recognized_text):\n",
    "                            frame_results[recognized_text[:11]] += 1\n",
    "                            draw.text((x1, y1 - 10), recognized_text[:11], fill=\"red\", font=font)\n",
    "                            \n",
    "                            total_count += 1\n",
    "                            if recognized_text[:11] == correct_number[:11]:\n",
    "                                correct_count += 1\n",
    "\n",
    "                frame_output_path = os.path.join(video_frames_folder, f\"{video_stem}_frame_{frame_idx}.jpg\")\n",
    "                image.save(frame_output_path)\n",
    "                frame_idx += 1\n",
    "                \n",
    "                processed_frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "                out.write(processed_frame)\n",
    "\n",
    "            video_capture.release()\n",
    "            out.release()\n",
    "\n",
    "            if frame_results:\n",
    "                final_number = max(frame_results, key=frame_results.get)\n",
    "                log_file.write(f\"Video: {video_file}, Final Container Number: {final_number}\\n\")\n",
    "                \n",
    "                if final_number == correct_number:\n",
    "                    log_file.write(f\"Video: {video_file}, Recognized correctly: {final_number}\\n\")\n",
    "                    overall_correct_count += 1\n",
    "                else:\n",
    "                    log_file.write(f\"Video: {video_file}, Recognized incorrectly: {final_number} (correct: {correct_number})\\n\")\n",
    "            else:\n",
    "                log_file.write(f\"Video: {video_file}, No valid container number detected\\n\")\n",
    "            \n",
    "            overall_total_count += 1\n",
    "\n",
    "            accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "            log_file.write(f\"Video: {video_file}, OCR Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    overall_accuracy = overall_correct_count / overall_total_count if overall_total_count > 0 else 0\n",
    "    log_file.write(f\"Overall OCR Accuracy: {overall_accuracy:.2f}\\n\")\n",
    "\n",
    "print(\"所有结果已记录在 results_log.txt 中。\")\n",
    "print(f\"Overall OCR Accuracy: {overall_accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
